{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import h5py \n",
    "import os \n",
    "import math \n",
    "import numpy as np\n",
    "import struct as st\n",
    "from PIL import Image\n",
    "import uuid\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import makro_utils as mu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = mu.load_MNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batches_x_only(x_train, mini_batch_size):\n",
    "    \n",
    "    m = x_train.shape[0]\n",
    "    num_of_complete_mini_batches = math.floor(m/(mini_batch_size))\n",
    "    mini_batches = []\n",
    "    \n",
    "    for k in range(0, num_of_complete_mini_batches):\n",
    "        mini_batch_x = x_train[k * mini_batch_size : k * mini_batch_size + mini_batch_size, :, :, :]\n",
    "        mini_batch = (mini_batch_x)\n",
    "        mini_batches.append(mini_batch)\n",
    "   \n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_x = x_train[num_of_complete_mini_batches * mini_batch_size : m, :, :, :]\n",
    "        mini_batch = (mini_batch_x)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.expand_dims(x_train, axis=3)\n",
    "minibatches = mini_batches_x_only(t, 10000)\n",
    "len(minibatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_probability(x_input, lts_size):\n",
    "    \n",
    "    mu = tf.layers.dense(inputs = x_input, units = lts_size, activation = 'sigmoid', name = 'mpt_mu_layer_in')\n",
    "    sigma = tf.layers.dense(inputs = x_input, units = lts_size, activation = 'sigmoid', name = 'mpt_sigma_layer_in')\n",
    "    \n",
    "    z = mu + sigma*tf.random.normal(tf.shape(mu), 0, 1, dtype = tf.float64)\n",
    "    \n",
    "    out = tf.layers.dense(inputs = z, units = x_input.get_shape().as_list()[1], activation = 'relu', name = 'mtp_out')\n",
    "    \n",
    "    return out, mu, sigma\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define forward propagation\n",
    "\n",
    "def ff(x_train, lts_size):\n",
    "    layer_conv2d_1 = tf.layers.conv2d(inputs = x_train, filters = 8, kernel_size = (3,3), name = \"conv_2d_1\", activation = 'relu')\n",
    "    #layer_max_pool_1 = tf.layers.max_pooling2d(layer_conv2d_1, pool_size = (2,2) , strides = 2, padding='valid', name=\"max_pool_1\")\n",
    "    \n",
    "    layer_conv2d_2 = tf.layers.conv2d(layer_conv2d_1, filters = 6, kernel_size = (3,3), name = \"conv_2d_2\", activation = 'relu')\n",
    "    layer_max_pool_2 = tf.layers.max_pooling2d(layer_conv2d_2, pool_size = (2,2) , strides = 2, padding='valid', name=\"max_pool_2\")\n",
    "    \n",
    "    layer_conv2d_3 = tf.layers.conv2d(layer_max_pool_2, filters = 4, kernel_size = (3,3), name = \"conv_2d_3\", activation = 'relu')\n",
    "    layer_max_pool_3 = tf.layers.max_pooling2d(layer_conv2d_3, pool_size = (2,2) , strides = 2, padding='valid', name=\"max_pool_3\")\n",
    "    \n",
    "    layer_flatten = tf.layers.flatten(layer_max_pool_3)\n",
    "    \n",
    "    mtp, mu, sigma = map_to_probability(layer_flatten, lts_size)\n",
    "    \n",
    "    layer_expand = tf.reshape(mtp, tf.shape(layer_max_pool_3))\n",
    "    \n",
    "    layer_unpool_3 = tf.image.resize_images(layer_expand, tf.constant([20,20], tf.int32))\n",
    "    layer_conv2d_3_decoder = tf.layers.conv2d(layer_unpool_3, filters = 4, kernel_size = (3, 3), strides = 2, padding=\"SAME\", activation=\"relu\")\n",
    "    \n",
    "    layer_unpool_2 = tf.image.resize_images(layer_conv2d_3_decoder, tf.constant([30,30], tf.int32))\n",
    "    layer_conv2d_2_decoder = tf.layers.conv2d(layer_unpool_2, filters = 3, kernel_size= (3, 3), strides = 2, padding=\"SAME\", activation=\"relu\")\n",
    "    \n",
    "    layer_unpool_1 = tf.image.resize_images(layer_conv2d_2_decoder, tf.constant([56,56], tf.int32))\n",
    "    layer_conv2d_1_decoder = tf.layers.conv2d(layer_unpool_1, filters = 1, kernel_size = (3, 3), strides = 2, padding=\"SAME\", activation=\"sigmoid\")\n",
    "    print(x_train.shape)\n",
    "    print(layer_conv2d_1.shape)\n",
    "    #print(layer_max_pool_1.shape)\n",
    "    print(layer_conv2d_2.shape)\n",
    "    print(layer_max_pool_2.shape)\n",
    "    print(layer_conv2d_3.shape)\n",
    "    print(layer_max_pool_3.shape)\n",
    "    print(layer_flatten.shape)\n",
    "    print(layer_expand.shape)\n",
    "    print(layer_unpool_3.shape)\n",
    "    print(layer_conv2d_3_decoder.shape)\n",
    "    print(layer_unpool_2.shape)\n",
    "    print(layer_conv2d_2_decoder.shape)\n",
    "    print(layer_unpool_1.shape)\n",
    "    print(layer_conv2d_1_decoder.shape)\n",
    "    \n",
    "    return layer_conv2d_1_decoder, mu, sigma\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-991bbfd5151f>:4: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f50a435fbe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f50a435fbe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f50a435fbe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f50a435fbe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f50a435fbe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f50a435fbe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f50a435fbe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f50a435fbe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-6-991bbfd5151f>:8: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f50a435fbe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f50a435fbe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f50a435fbe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f50a435fbe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f50a435fbe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f50a435fbe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f50a435fbe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f50a435fbe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f5078bcde10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f5078bcde10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f5078bcde10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f5078bcde10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-6-991bbfd5151f>:13: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f5078bcde10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f5078bcde10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f5078bcde10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f5078bcde10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From <ipython-input-5-b21cc6009eb6>:3: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f5078bcde10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f5078bcde10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f5078bcde10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f5078bcde10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f5078bcde10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f5078bcde10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f5078bcde10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f5078bcde10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f5078bcde10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f5078bcde10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f5078bcde10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f5078bcde10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505bf40c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505bf40c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505bf40c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505bf40c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505bf40c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505bf40c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505bf40c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505bf40c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505bf40c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505bf40c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505bf40c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505bf40c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "(?, 28, 28, 1)\n",
      "(?, 26, 26, 8)\n",
      "(?, 24, 24, 6)\n",
      "(?, 12, 12, 6)\n",
      "(?, 10, 10, 4)\n",
      "(?, 5, 5, 4)\n",
      "(?, 100)\n",
      "(?, 5, 5, 4)\n",
      "(?, 20, 20, 4)\n",
      "(?, 10, 10, 4)\n",
      "(?, 30, 30, 4)\n",
      "(?, 15, 15, 3)\n",
      "(?, 56, 56, 3)\n",
      "(?, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "ops.reset_default_graph() \n",
    "t = x_train\n",
    "X = tf.placeholder(tf.float64, shape = (None ,t.shape[1], t.shape[2], 1))\n",
    "Y = tf.placeholder(tf.float64, shape = (None ,t.shape[1], t.shape[2], 1))\n",
    "X.shape\n",
    "\n",
    "y_predicted, mu, sigma = ff(X, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x_train, lts_size = 20, learning_rate = 0.001, num_epochs = 100, minibatch_size = 10000, print_cost = True):\n",
    "    \n",
    "    x_train = np.expand_dims(x_train, axis=3)\n",
    "    ops.reset_default_graph() \n",
    "      \n",
    "    m = x_train.shape[0]  \n",
    "    costs = []                                                             \n",
    "    #Create placeholders\n",
    "    X = tf.placeholder(tf.float64, shape = (None ,x_train.shape[1], x_train.shape[2], 1))\n",
    "   \n",
    "    \n",
    "    \n",
    "    #Define loss function\n",
    "    y_predicted, mu, sigma = ff(X, lts_size)\n",
    "    y_predicted = tf.cast(y_predicted, tf.float64)\n",
    "    reconstruction_loss = tf.reduce_mean(tf.square(X - y_predicted))\n",
    "    KL_divergence =  0.5*tf.reduce_mean(tf.square(mu) + tf.square(sigma) - tf.log(1e-8 + tf.square(sigma)) - 1)   # Kullback–Leibler divergence\n",
    "    loss = reconstruction_loss + 0.001*KL_divergence\n",
    "    \n",
    "    #Initialize parameters and define optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "    np.random.shuffle(x_train)\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        #Initialize variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        #Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            print(\"\\nStarting epoch: \", epoch)\n",
    "            \n",
    "            \n",
    "            \n",
    "            epoch_cost = 0.          \n",
    "            num_minibatches = int(m / minibatch_size) \n",
    "            minibatches = mini_batches_x_only(x_train, minibatch_size)\n",
    "            i = 0\n",
    "            for minibatch in minibatches:\n",
    "                i = 1 + i\n",
    "                print(\"Minibatch index:\", i, end=\"\\r\", flush=True)\n",
    "            \n",
    "                _, minibatch_cost, KL, rl = sess.run([optimizer, loss, KL_divergence, reconstruction_loss], feed_dict = {X: minibatch})\n",
    "                \n",
    "                epoch_cost = epoch_cost + minibatch_cost / num_minibatches\n",
    "                \n",
    "            np.random.shuffle(x_train)    \n",
    "              \n",
    "                    \n",
    "            if print_cost == True:\n",
    "                costs.append(epoch_cost)\n",
    "            if epoch % 2 == 0:\n",
    "                print(\"Epoch_cost:\", epoch_cost)\n",
    "                print(\"Epoch_rl cost:\", rl)\n",
    "                print(\"Epoch_KL cost:\", KL)\n",
    "                a, b = sess.run([y_predicted, X], feed_dict = {X : x_train[0:1]})   \n",
    "                plt.imshow(a[0,:,:,0])\n",
    "                plt.show()\n",
    "                plt.imshow(b[0,:,:,0])\n",
    "                plt.show()\n",
    "                \n",
    "                \n",
    "                \n",
    "        saver.save(sess, 'model/vae/vae')        \n",
    "        #Plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per fives)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "            \n",
    "             \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505bf335f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505bf335f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505bf335f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505bf335f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505b57ec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505b57ec50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505b57ec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505b57ec50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f505b57ec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f505b57ec50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f505b57ec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f505b57ec50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505b57ec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505b57ec50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505b57ec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505b57ec50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f505b57ec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f505b57ec50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f505b57ec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f505b57ec50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f505b57ec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f505b57ec50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f505b57ec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f505b57ec50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f505b57ec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f505b57ec50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f505b57ec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f505b57ec50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f505b57ec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f505b57ec50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f505b57ec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f505b57ec50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f505b5fa9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f505b5fa9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f505b5fa9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f505b5fa9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505b63cc18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505b63cc18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505b63cc18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505b63cc18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505b3f35c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505b3f35c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505b3f35c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505b3f35c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505b3f35c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505b3f35c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505b3f35c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f505b3f35c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "(?, 28, 28, 1)\n",
      "(?, 26, 26, 8)\n",
      "(?, 24, 24, 6)\n",
      "(?, 12, 12, 6)\n",
      "(?, 10, 10, 4)\n",
      "(?, 5, 5, 4)\n",
      "(?, 100)\n",
      "(?, 5, 5, 4)\n",
      "(?, 20, 20, 4)\n",
      "(?, 10, 10, 4)\n",
      "(?, 30, 30, 4)\n",
      "(?, 15, 15, 3)\n",
      "(?, 56, 56, 3)\n",
      "(?, 28, 28, 1)\n",
      "\n",
      "Starting epoch:  0\n",
      "Epoch_cost: 0.08549234913580497\n",
      "Epoch_rl cost: 0.05961266224795888\n",
      "Epoch_KL cost: 2.011795841390996\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting epoch:  1\n",
      "Minibatch index: 198\r"
     ]
    }
   ],
   "source": [
    "model(x_train/255, lts_size = 40, learning_rate = 0.001, num_epochs = 400, minibatch_size = 256, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
